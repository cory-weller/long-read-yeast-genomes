# module load snakemake
# test: snakemake -n -r
# interactive run: snakemake --cores 2
# cluster run: snakemake -s Snakefile_s288c-orf -j 16 --latency-wait 120 --cluster="sbatch -p quick"
# module load graphviz
# snakemake --dag | dot -Tsvg > dag.svg

# use the wildcards from bottom-up

configfile: "config_s288c-orf.yaml"

REF = config['reference']
SAMPLES = config['samples'] # pacbio genomes
ALL_SAMPLES = [REF] + SAMPLES

localrules: all
rule all:
    input:
        expand("data/unique_orfs_2/{all_samples}_unique.fa", all_samples=ALL_SAMPLES) # fastq > pear

rule blastp:
    # pull orfs from each blastdb and blast against the reference
    input:
        query="data/blastdb/{all_samples}.fa",
        check_db=multiext("data/blastdb/{all_samples}.fa", ".pdb",".phr",".pin",".pjs",".pot",".psq",".ptf",".pto"),
        db=f"data/blastdb/{REF}.fa"
    output: "data/blastp_s288c_orf/{all_samples}.tsv"
    params:
        module="blast/2.13.0+"
    threads: 4
    shell:
        """
        module load {params.module}
        blastp -num_threads {threads} -outfmt 6 -max_hsps=1 -db {input.db} -query {input.query} -out {output}
        """

rule unique_orfs:
    # python script to extract unique orfs from each blast search
    # NOTE: conda activate alignparse-environment must be done manually
    input:
        orfs="data/blastdb/{all_samples}.fa",
        blast_hits="data/blastp_s288c_orf/{all_samples}.tsv"
    output: "data/unique_orfs_2/{all_samples}_unique.fa"
    params:
        conda_env="alignparse-environment" # may not work
    threads: 1
    shell:
        """
        python scripts/unique_orfs.py -orfs {input.orfs} -blast {input.blast_hits} -out {output}
        """
